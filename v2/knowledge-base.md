# Rhode Island Department of Education (RIDE)
## Artificial Intelligence (AI) Guidance – August 2025 (Expanded Summary)

---

## 1. Purpose & Context
The **RIDE AI Guidance** establishes a statewide framework for the safe, equitable, and effective use of Artificial Intelligence (AI) in K–12 schools.  
It supports Local Education Agencies (LEAs) in developing policies, professional learning plans, and implementation strategies.

> This guidance is a *living, non-regulatory document* designed to adapt as AI evolves.

### Why It Was Created
RIDE observed:
- Students increasingly use AI tools such as ChatGPT, Grammarly, Photomath, and image generators.  
- Many teachers and administrators lack training, clarity, or policies to guide safe use.  
- AI presents opportunities for **personalized learning**, **efficiency**, and **equity**, but also introduces risks.

### Core Goals
- Enhance teaching and learning  
- Protect student data and privacy  
- Ensure equitable access  
- Support ethical use and academic integrity  
- Prepare students for an AI-driven workforce  

### Stakeholder Input (Extensive)
RIDE collected data from:
- **1,252** stakeholders (students, educators, administrators, families)  
- **9** RIDE leadership interviews  
- **9** focus groups  
- **3** statewide town halls  
- **5** expert “Lunch & Learn” events  
- National and state AI guidance reviews  

RIDE will continue updating the guidance and will offer statewide professional learning beginning in **2025**.

---

## 2. Mission & Vision

### RIDE Mission
- Provide a unified, strategic direction for education across Rhode Island.  
- Use policy and governance to expand opportunities for **all** students.  
- Foster innovation, efficiency, collaboration, and continuous learning.

### AI Vision
RIDE’s vision for AI:
- AI should **empower teachers**, not replace them.  
- AI should help level the playing field for students.  
- AI should enhance personalization, engagement, and instructional quality.  
- AI must be used **ethically, equitably, and safely**, with strong human oversight.

RIDE emphasizes that human educators remain **irreplaceable**.  
AI is a tool — not a substitute for teacher judgment or relationships.

---

## 3. Strategic Alignment

RIDE’s AI guidance aligns with *Together Through Opportunity: Pathways to Student Success (2021–2027)*.

| Strategic Priority | AI Connection |
|--------------------|---------------|
| **Equity** | Use AI to close opportunity gaps and support underserved groups. |
| **Excellence in Learning** | Support blended, personalized, and adaptive learning aligned to grade-level standards. |
| **Engaged Communities** | Co-develop policies with students, families, educators, and community partners. |
| **World-Class Talent** | Build AI literacy and professional capacity across the workforce. |
| **Governance Structures** | Provide guidance, policy frameworks, and consistent expectations statewide. |

RIDE also participates in the **State of Rhode Island’s AI Task Force**.

---

## 4. Instructional Guidance

### Potential Benefits of AI in Instruction
- Personalized instruction that adapts to student needs  
- Timely feedback for writing, math problem solving, language learning  
- Interactive learning experiences (simulations, role-play, examples)  
- Differentiation for multilingual learners (MLLs) and differently-abled students (DAS)  
- Teacher time savings on planning, drafting emails, creating rubrics, or generating practice questions  
- Improved engagement for students who benefit from multimodal learning  
- Preparation for AI-enabled careers and higher education  

### Risks & Pitfalls
- Academic dishonesty and misuse  
- Over-dependence on AI, reducing critical thinking  
- Inconsistent access leading to inequitable outcomes  
- AI-generated inaccuracies, bias, or misalignment with grade-level standards  
- Reduced teacher-student connection if not balanced  
- Exposure to inappropriate content if tools are not vetted  
- Data privacy concerns (sharing student work with external AI tools)  

### Pathways for Implementation
- Provide **professional development** for educators (requested PD topics include AI literacy, ethics, equity, instructional uses).  
- Create **district AI taskforces** with diverse perspectives.  
- Build **AI literacy programs** for students (age-appropriate).  
- Develop clear **ethical use policies**, requiring:  
  - Documentation of prompts  
  - Disclosure and citation of AI use  
  - Clear boundaries for acceptable vs. unacceptable use  
- Ensure AI supplements, not replaces, student thinking.  
- Incorporate **performance-based assessments** to confirm authentic skill mastery.  
- Provide equal access to AI tools for students and educators.

---

## 5. Developmentally Appropriate Use

| Grade Band | Appropriate Use | Key Risks |
|-----------|------------------|-----------|
| **K–2** | Highly supervised use of vetted tools; basic interactions; understanding that AI is not a person. | Confusion between real vs. fictional responses; high susceptibility to suggestion. |
| **3–5** | Vocabulary help, grammar checks, fact-finding; teacher-guided exploration. | Misinterpreting AI inaccuracies; dependency on AI for basic problem-solving. |
| **6–8** | Critiquing AI responses; comparing reasoning; structured prompts; basics of bias and misinformation. | Impulse misuse; deepfake creation; cyberbullying in early adolescence. |
| **9–12** | Brainstorming, refinement, simulations, self-testing; analyzing bias; using AI for career exploration. | Over-reliance; lack of independent academic skills if unbalanced. |

AI use must be adapted for students with unique needs (DAS, MLL).

---

## 6. Academic Integrity
RIDE highlights the need for **clear, universal definitions** of cheating.

Key guidance:
- Students must **cite AI use** in assignments.  
- Teachers must clearly define when AI:  
  - is allowed  
  - is partially allowed  
  - is prohibited  
- AI accommodations for DAS should **not** be penalized.  
- Transparency is essential — students should record prompts and outputs used.

Recommended reference policies include:
- North Carolina DPI AI Guidelines  
- Greenwich Public Schools' AI Policy  
- TeachAI Acceptable Use models  

---

## 7. Equity & Bias

### Stakeholder Perception Findings
- **60% of families** believe AI can reduce disparities.  
- Only **31% of educators** agree.  
- **53% of families** worry about AI bias; fewer (39%) educators share that concern.  
- Less than half of educators believe all students will receive equal AI access.

### Equity Opportunities
- Personalized, adaptive learning for underserved students  
- On-demand translation for MLL families  
- Expanded access to tutoring  
- Analytics that reveal inequities in scheduling, discipline, and instruction  
- Automating administrative tasks so teachers can focus on high-need students  

### Equity Risks
- Biased or culturally insensitive outputs  
- Systems trained on unequal data reinforcing inequities  
- Digital divide across schools or districts  
- Decreased human interaction for high-need students  
- AI tools that are not aligned with grade-level expectations  

### Equity Pathways
- Maintain strong **human oversight**.  
- Provide **robust training** on AI fairness and bias.  
- Engage families — especially multilingual and marginalized groups — in AI policy development.  
- Translate communications into multiple languages.  
- Monitor AI use and outcomes by subgroup.  
- Clearly communicate data-use practices and privacy protections.

---

## 8. Meeting the Needs of Diverse Learners (DAS & MLL)

### Opportunities
- Adaptive tools that adjust difficulty and pacing  
- Translation and language scaffolding  
- Audiovisual supports: text-to-speech, image description, transcripts  
- Step-by-step cognitive scaffolding for complex tasks  
- Safe, low-stakes environments to practice English or academic skills  
- Writing support with immediate feedback  

### Risks
- Loss of essential human connection  
- Privacy risks with sensitive student data  
- Culturally inaccurate or biased translations  
- Improper use that prevents skill development  
- Widening gaps if tech access is uneven  

### Pathways
- Integrate **AI literacy** into MTSS, multilingual, and special education programs.  
- Use AI to enhance — not replace — human instruction.  
- Provide **specialized PD** for teachers of MLLs and DAS.  
- Continuously evaluate tools for accessibility, accuracy, and cultural relevance.  
- Engage families in conversations about tools used with their children.  

---

## 9. Security & Safety

### Governing Laws
- **FERPA** – Student data protections  
- **COPPA** – Consent for under 13  
- **CIPA** – Internet filtering and digital citizenship  
- **PPRA** – Limits on survey data collection  
- **HIPAA** – Health data protections  

### Key Privacy Principles
- Never upload personally identifiable information (PII) to external AI tools  
- Enforce “**privacy by default**”  
- Prevent use of student data for model training  
- Ensure staff and students receive training on safe use  

### Safety Risks
- Black-box algorithms lacking transparency  
- Inappropriate content surfacing in AI tools  
- Deepfakes and cyberbullying  
- Biased outputs  
- Behavioral profiling  

### Pathways for Safety
- Require vendor **transparency**, audits, and U.S.-based data storage  
- Establish **incident response** and breach notification protocols  
- Create a district **Data Security Officer** role  
- Maintain alternative lesson plans in case of system failure  
- Prefer secure, education-focused LLMs (“walled gardens”)  

---

## 10. College & Career Readiness

### Context
Over **85% of U.S. businesses** use AI.  
Students must understand AI to be competitive.

### Opportunities
- Personalized career recommendations  
- Skill gap identification  
- AI-powered virtual internships  
- Labor market forecasting  
- Support with college essays and applications  

### Pitfalls
- Biased recommendations narrowing aspirations  
- Overreliance on predictive tools  
- Underdeveloped soft skills  
- Access inequities  

### Pathways
- Blend AI tools with human mentoring  
- Teach AI literacy as a graduation-readiness skill  
- Partner with industry advisory boards  
- Provide exposure to emerging AI-driven careers  
- Update tools annually to reflect evolving workforce needs  

---

## 11. LEA Operations, Administration & Communications

### Opportunities
- Data analytics for decision-making  
- Predictive modeling (enrollment, staffing, intervention needs)  
- Automated communications with translation  
- Route planning, energy efficiency, inventory management  
- Bias-aware discipline decision support  

### Risks
- Misinterpreting AI analytics  
- Data privacy breaches  
- Biased operational outputs  
- Over-reliance on algorithms  

### Pathways
- Develop **AI governance structures**  
- Update **procurement** to include privacy, bias, and ethics clauses  
- Use **audits** to ensure fairness and accuracy  
- Maintain **human oversight** in final decisions  
- Use structured **data interpretation protocols**  
- Communicate transparently with staff and families  

---

## 12. Family, Caregiver & Community Engagement

### Parent Survey Findings
- Only **33%** trust the school to protect their child’s data  
- **72%** want the ability to opt out  
- **89%** want ongoing communication about AI  
- Only **27%** believe AI makes learning more compelling  

### Opportunities
- Instant translation  
- 24/7 chatbots for school info  
- Personalized communications  
- Data-driven outreach strategies  

### Risks
- Misinterpretation of AI messages  
- Cultural insensitivity  
- Overreliance on automated communication  
- Privacy concerns  

### Pathways
- Maintain human review of AI communications  
- Provide digital literacy support for families  
- Offer transparency and opt-out options  
- Create community-facing AI education resources  
- Include families in AI committees  

---

## 13. Conclusion & Next Steps

RIDE encourages every LEA to:
- Develop a **local AI plan**  
- Form an **AI Task Force**  
- Adopt **clear policies**  
- Train educators, staff, and students  
- Prioritize equity and privacy  
- Communicate openly with families  
- Use RIDE’s checklists to guide implementation and procurement  

AI, when used thoughtfully, can improve learning, increase efficiency, and expand opportunity — **while keeping human educators at the center**.

---

## 14. Appendices (Condensed)

### A. Conversation Starters
Parents, teachers, administrators, and school boards receive targeted questions to guide local AI discussions.

### B. LEA “Getting Started with AI” Checklist
Covers governance, implementation, training, monitoring, and communication.

### C. AI Procurement Checklist
Includes requirements for data privacy, transparency, cybersecurity, equity, contractual protections, and vendor accountability.

### D. Sample Parent Letter
Outlines principles for safe AI use, consent requirements, and district commitments.

---

# End of Summary
